[2024-10-04T08:14:03.460+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: airflow-mnist.evaluate manual__2024-10-04T08:13:50.275643+00:00 [queued]>
[2024-10-04T08:14:03.466+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: airflow-mnist.evaluate manual__2024-10-04T08:13:50.275643+00:00 [queued]>
[2024-10-04T08:14:03.466+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2024-10-04T08:14:03.467+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 2
[2024-10-04T08:14:03.467+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2024-10-04T08:14:03.476+0000] {taskinstance.py:1300} INFO - Executing <Task(BashOperator): evaluate> on 2024-10-04 08:13:50.275643+00:00
[2024-10-04T08:14:03.482+0000] {standard_task_runner.py:55} INFO - Started process 635 to run task
[2024-10-04T08:14:03.485+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', '***-mnist', 'evaluate', 'manual__2024-10-04T08:13:50.275643+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/src/main.py', '--cfg-path', '/tmp/tmpv3ftikit']
[2024-10-04T08:14:03.485+0000] {standard_task_runner.py:83} INFO - Job 5: Subtask evaluate
[2024-10-04T08:14:03.529+0000] {task_command.py:388} INFO - Running <TaskInstance: airflow-mnist.evaluate manual__2024-10-04T08:13:50.275643+00:00 [running]> on host be56adf0b2de
[2024-10-04T08:14:03.578+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=***-mnist
AIRFLOW_CTX_TASK_ID=evaluate
AIRFLOW_CTX_EXECUTION_DATE=2024-10-04T08:13:50.275643+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-10-04T08:13:50.275643+00:00
[2024-10-04T08:14:03.579+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2024-10-04T08:14:03.579+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /opt/***/dags/src/evaluate.py --data_path /home/***/gcs/data/mnist/test/mnist.npz --model_path /home/***/gcs/data/models/mnist_linear_saved_model --log_path /home/***/gcs/data/training-result.log']
[2024-10-04T08:14:03.593+0000] {subprocess.py:86} INFO - Output:
[2024-10-04T08:14:03.705+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:03.705537: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
[2024-10-04T08:14:03.705+0000] {subprocess.py:93} INFO - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2024-10-04T08:14:03.806+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:03.806780: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib
[2024-10-04T08:14:03.807+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:03.806804: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[2024-10-04T08:14:03.824+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:03.824798: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
[2024-10-04T08:14:04.579+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:04.579514: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib
[2024-10-04T08:14:04.579+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:04.579577: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib
[2024-10-04T08:14:04.579+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:04.579587: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[2024-10-04T08:14:05.515+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:05.514928: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib
[2024-10-04T08:14:05.515+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:05.514954: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
[2024-10-04T08:14:05.515+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:05.514972: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist
[2024-10-04T08:14:05.515+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:05.515123: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
[2024-10-04T08:14:05.515+0000] {subprocess.py:93} INFO - To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2024-10-04T08:14:06.008+0000] {subprocess.py:93} INFO -   1/313 [..............................] - ETA: 31s - loss: 0.0608 - accuracy: 0.9688 82/313 [======>.......................] - ETA: 0s - loss: 0.1781 - accuracy: 0.9474 167/313 [===============>..............] - ETA: 0s - loss: 0.1688 - accuracy: 0.9508253/313 [=======================>......] - ETA: 0s - loss: 0.1427 - accuracy: 0.9589313/313 [==============================] - 0s 597us/step - loss: 0.1330 - accuracy: 0.9622
[2024-10-04T08:14:06.009+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:06,009 - ***-mnist - INFO - model, /home/***/gcs/data/models/mnist_linear_saved_model
[2024-10-04T08:14:06.009+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:06,009 - ***-mnist - INFO - loss, 0.13304582238197327
[2024-10-04T08:14:06.009+0000] {subprocess.py:93} INFO - 2024-10-04 08:14:06,009 - ***-mnist - INFO - acc, 0.9621999859809875
[2024-10-04T08:14:06.009+0000] {subprocess.py:93} INFO - -----model----
[2024-10-04T08:14:06.009+0000] {subprocess.py:93} INFO - loss: 0.1330 acc: 0.9622
[2024-10-04T08:14:06.355+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2024-10-04T08:14:06.376+0000] {taskinstance.py:1323} INFO - Marking task as SUCCESS. dag_id=***-mnist, task_id=evaluate, execution_date=20241004T081350, start_date=20241004T081403, end_date=20241004T081406
[2024-10-04T08:14:06.422+0000] {local_task_job.py:208} INFO - Task exited with return code 0
[2024-10-04T08:14:06.437+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
